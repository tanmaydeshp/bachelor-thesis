{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2839e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import filtering  \n",
    "# df = filtering.moses_to_df(\"data/en-si/Ubuntu.en-si.en\", \"data/en-si/Ubuntu.en-si.si\", \"english\", \"sinhala\")\n",
    "# e1 = filtering.to_multilingual_embedding(\"english\", df[\"english\"], \"labse\")\n",
    "# e2 = filtering.to_multilingual_embedding(\"sinhala\", df[\"sinhala\"], \"labse\")\n",
    "# ss = filtering.find_similarity_score(e1, e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3162a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bucc_style_dataset as bsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e872dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "si_mono_lines = []\n",
    "eng_mono_lines = []\n",
    "with open(\"data/en-si/sin_wikipedia_2021_30K-sentences.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.removesuffix(\"\\n\")\n",
    "        split  =line.split(\"\\t\")\n",
    "        si_mono_lines.append(split[1])\n",
    "with open(\"data/en-si/eng_news_2024_30K-sentences.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f: \n",
    "        line = line.removesuffix(\"\\n\")\n",
    "        split  =line.split(\"\\t\")\n",
    "        eng_mono_lines.append(split[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ca0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "si_par_lines = []\n",
    "eng_par_lines = []\n",
    "with open(\"data/en-si/eng_Latn.dev\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.removesuffix(\"\\n\")\n",
    "        eng_par_lines.append(line)\n",
    "with open(\"data/en-si/sin_Sinh.dev\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f: \n",
    "        line = line.removesuffix(\"\\n\")\n",
    "        si_par_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f653d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 30000.\n",
      "7500 22500\n",
      "Dataset length: 30000.\n",
      "7500 22500\n",
      "Dataset length: 997.\n",
      "249 748\n",
      "Dataset length: 997.\n",
      "249 748\n",
      "False False False False\n",
      "7500 monolingual source sentences.\n",
      "7500 monolingual target sentences.\n",
      "Whole corpus:\n",
      "7749 monolingual source sentences.\n",
      "7749 monolingual target sentences.\n",
      "src-0000000\tA staggering $1.96 million in ENA tokens were awarded to the highest airdrop recipient, demonstrating the significant impact of this distribution. trg-0000000\tඇසිපිල්ලම් තුනීසිවියකින් (ආරක්ෂාකාරී තුන්වන ඇසිපිය) යුක්ත ඇස් විශාල වටකුරු ස්වභාවයක් ගනීයි.\n",
      "22500 monolingual source sentences.\n",
      "22500 monolingual target sentences.\n",
      "Whole corpus:\n",
      "23248 monolingual source sentences.\n",
      "23248 monolingual target sentences.\n",
      "src-0000000\tI have written to Sky New registering my disappointment with them, suggest others do the same. trg-0000000\tප්‍රවෘති ඉදිරිපත් කරන්නන්ගේ බොහෝ පුවත් “ පාර්සල් ස්වරූපයක් ගනී’.\n"
     ]
    }
   ],
   "source": [
    "train_list, test_list = bsd.split_shuffle_create_corpus(eng_mono_lines, si_mono_lines, eng_par_lines, si_par_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "748d6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_list = train_list[0].split(\"\\n\")\n",
    "si_list = train_list[1].split(\"\\n\")\n",
    "en_corpus_lines = []\n",
    "si_corpus_lines = []\n",
    "for line in en_list:\n",
    "    line = line.split(\"\\t\")[1]\n",
    "    en_corpus_lines.append(line)\n",
    "for line in si_list:\n",
    "    line = line.split(\"\\t\")[1]\n",
    "    si_corpus_lines.append(line)\n",
    "import filtering\n",
    "e1 = filtering.to_multilingual_embedding(\"english\", en_corpus_lines, \"labse\")\n",
    "e2 = filtering.to_multilingual_embedding(\"sinhala\", si_corpus_lines, \"labse\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd150ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lines = [f\"{e1.shape[0]} {e1.shape[1]}\"]\n",
    "target_lines = [f\"{e2.shape[0]} {e2.shape[1]}\"]\n",
    "for sent, encoding in zip(en_corpus_lines, e1):\n",
    "    sent = sent.replace(\" \", \"_\")\n",
    "    encoding_str = \" \".join([f\"{x:.4f}\" for x in encoding])\n",
    "    source_lines.append(f\"{sent} {encoding_str}\")\n",
    "for sent, encoding in zip(si_corpus_lines, e2):\n",
    "    sent = sent.replace(\" \", \"_\")\n",
    "    encoding_str = \" \".join([f\"{x:.4f}\" for x in encoding])\n",
    "    target_lines.append(f\"{sent} {encoding_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d83c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"source.vec\", \"w\", encoding=\"utf-8\") as f: \n",
    "    for line in source_lines:\n",
    "        f.write(f\"{line}\\n\")\n",
    "with open(\"target.vec\", \"w\", encoding=\"utf-8\") as f: \n",
    "    for line in target_lines:\n",
    "        f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b94ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Running search query...\n",
      "WARNING:root:Saving results...\n"
     ]
    }
   ],
   "source": [
    "import bilingual_nearest_neighbor as bnn \n",
    "bnn.main(source_embeddings=\"evaluation/en.source.vec\", target_embeddings=\"evaluation/si.target.vec\", output=\"evaluation/en-si.output.txt\", binary=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87e54ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_file_dict = {}\n",
    "with open(\"data/en-si/eng_Latn.dev\", \"r\", encoding=\"utf-8\") as f1, open(\"data/en-si/sin_Sinh.dev\", \"r\", encoding=\"utf-8\") as f2:\n",
    "    for line1, line2 in zip(f1, f2):\n",
    "        line1 = line1.removesuffix(\"\\n\")\n",
    "        line2 = line2.removesuffix(\"\\n\")\n",
    "        line1 = line1.replace(\"\\u200d\", \"\")\n",
    "        line2 = line2.replace(\"\\u200d\", \"\")\n",
    "        gold_file_dict[line1] = line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f1d5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evaluation/en-si.output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_dict = {}\n",
    "    for line in f:\n",
    "        split = line.split(\"\\t\")\n",
    "        split = [item.replace(\"_\", \" \") for item in split]\n",
    "        split = [item.replace(\"\\u200d\", \"\") for item in split]\n",
    "        split = split[:2]\n",
    "        if split[0] in gold_file_dict.keys():\n",
    "            test_dict[split[0]] = split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4741d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evaluation/mined.en\", \"w\", encoding=\"utf-8\") as f1, open(\"evaluation/mined.si\", \"w\", encoding=\"utf-8\") as f2:\n",
    "    for s1, s2 in test_dict.items():\n",
    "        f1.write(s1 + \"\\n\")\n",
    "        f2.write(s2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d375d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import filtering \n",
    "filtering.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
